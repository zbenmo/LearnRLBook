## Chapter 1. Searching for the best course of action

Consider we're trying to automate a warehouse. We have a representation of the exact location of every item in the warehouse.
To retrieve a specific item, one may need to move first other items that are in the item's way (or above it for example).
Now, we're given a request for an item.
If the item is accessable, a robotic arm can reach for it, place it on the moving belt, and we'll collect it on the other end of the belt. If however the item is somewhat hidden behind other items, some planning is needed.
For example moving the blocking items to another place first, and so revealing the desired item. Once the item becomes accessible, the robotic arm can proceeed as before.
Planning can be done by searching the space of options. Options are actions such as picking an item and placing it in another place.
If the current warehouse representation is a state, then the warehouse as it will look after a potential action is another state.
Planning should come up with an efficient and effective series of actions that will lead in theory to the item being accessible.
Once the plan is computed by a search algorithm, it is then executed, moving items to reveal the desired item. If all goes well, the final locations of the items, reflected by the software representation, enables the robotic arm to fetch the desire item, and sending it to us using the moving belt.

To better understand the concept of search, let's think about the Chess game. We want to build a software that plays agaist a human and give a good fight. For the sake of discussion, we're in the initial board state and the software plays the White. The software can make any legitimate move, a thing that will hopefully bring it closer to victory. Once a move is done by the White, given that we haven't won yet, or the board is not a stalemate then the Black gets a change to make his move. The move of the Black also changes the state of the board of course. So a planning here should take into account also that the other player will also try to win, and hence we should avoid leaving the board in a winnable state (winnable for the other side). In some problems or puzzles it is possible to exlusively explore in reasonable time, all possible developments in the state space and select the best path (ex. potentially win while never lose in Tic-Tac-Toe). In Chess and in many other games or real world settings, a search is possible yet only to a certain depth. Therefore will not be able to see all future developments, and we must act based on some heuristic. For example we can estimate if a Chess board is good for us based on the number of squares that we are in control of minus the number of squares that the opponent is in control of. Such heuristic helps both in directing the search, and in choosing what seems to be as the best move or action.

Search and planning are considered Artificial Inteligence (AI). Under the wide umbrella of AI, we find approaces for solving problems, not by instructing the machine directly How to address a challenge, but rather What is a desired outcome.
With Chess we wanted to convey to the software to find the way to win. We show the machine what it means to win or to lose, and we want it to come up with the sequence of moves that will lead to the final winning move. Not everything is in our control. The opponent chooses its own moves. He/she also wants to win or at least to avoid a loss. More than that, knowning that our software cannot inspect all the possible branches from the current state to all final states (win/lose/statemate), we had to help the search by providing a hand tailured heuristic. In the example above, the heuristic is a function from a board to a real value representing the value of the board or state from the player's viewpoint.

While Chess seams to be hard, the game is still well defined and controlled setting. The number of levers that a player can pull at any given turn is finite and small. A player can choose any one of a valid next move. Then he/she/it needs to wait for their next turn. When selecting a move, there is certenty regarding the next board state, as dictated by the game's rules. Both players have full knowledge of the current state, can write down past moves, and can plan and speculate about future moves. The only uncertenty is what the opponent will do next. And still Chess is very interesting as we cannot see all the possible futures and who will win.

A common introduction to RL is the k-Armed Bandits. You are standing front of k slot machines in Las-Vegas. To play a machine you pay $1 and pull the relevant lever. You then collect the winnings, if any, and continue if you wish and can afford it. For simplicity let's assume you play exactly 20 rounds. It is known to you that each of those machines has a different expected reward (average win). Would be nice to know which of those has the highest reward. Unfortunately there is no external hint. What you can do, is to try all and attempt to figure-out which one it is. The expected reward of a machine will not change over time, and that is nice to know. However since we're talking about expectations, we're never sure if we got it right. For example, let's say k=3. You've tried the three machines and got the following wins, $2, $0, $0 respectively. It seems that the first machine is the best, yet it might have been by chance. You're now left with a dilemma. To exploit your current belief and stick with the first machine, or explore a little more the other machines, just to be sure. What is the best policy here? Can we search for the optimal solution? With any additional exploration we increase our understanding of the environment, yet also waste a chance to exploit our knowledge. Assuming we are trying to maximizing the total amount of money we have in our pocket at the end of the day, we might decide to invest in exploration also, but probably not when we make the last attempt (the 20'th round in the example).

Let's briefly compare Chess, and the k-Armed Bandits. In both we are trying to find the best course of action. In Chess the rules are clear. It is a two playes game with interliving turns. When we make a move the result is deterministic. Then the opponent makes a move which is in his/her control. In Chess there is a natural end with an outcome of Win/Lose/Stalemate. In the k-Armed Bandits, there is an element of uncertaintly, that is what is the expected reward of each of the machines. And then an element of randomness, what will the current pull reward us (even if we knew for certain the expected reward for the specific machine).
In Chess there is an advantage to those who can evaluate better a board, plan deeper and remember patterns and learn from experience and from the masters. In the k-Armed Bandits, there is an advantage to a smart exploitation/exploration scheme. The outcome of the k-Armed Bandits is, for example, the total wins after a fixed amount of rounds, which we don't know if was the maximum possible or not, but we can compare an average performance over a large number of trials with another strategy.

If we try to build a self-driving car. Which of above is closer? Is self-driving car more like playing Chess or rather like the k-Armed Bandits?

